import unittest
import asyncio
import pytest
from unittest.mock import Mock, patch, AsyncMock
import sys
import os
import numpy as np
from datetime import datetime, timedelta

# Add the project root to the Python path
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '../..')))

from metrics.adversarial_metrics import AdversarialMetrics
from metrics.cognitive_metrics import CognitiveMetrics
from metrics.cost_metrics import CostMetrics
from metrics.finance_metrics import FinanceMetrics
from metrics.marketing_metrics import MarketingMetrics
from metrics.operations_metrics import OperationsMetrics
from metrics.stress_metrics import StressMetrics
from metrics.trust_metrics import TrustMetrics
from metrics.metric_suite import MetricSuite


class TestAdversarialMetrics(unittest.TestCase):
    """Test suite for the AdversarialMetrics class."""
    
    def setUp(self):
        """Set up test fixtures before each test method."""
        self.adversarial_metrics = AdversarialMetrics()
    
    def test_adversarial_metrics_initialization(self):
        """Test that the adversarial metrics initialize correctly."""
        self.assertIsNotNone(self.adversarial_metrics)
        self.assertEqual(len(self.adversarial_metrics._metrics), 0)
    
    def test_calculate_robustness_score(self):
        """Test calculating robustness score."""
        # Mock test data
        test_data = {
            "normal_performance": 0.9,
            "adversarial_performance": 0.7,
            "perturbation_types": ["noise", "occlusion", "adversarial_examples"],
            "perturbation_magnitudes": [0.1, 0.2, 0.3]
        }
        
        robustness_score = self.adversarial_metrics.calculate_robustness_score(test_data)
        
        self.assertIsNotNone(robustness_score)
        self.assertGreaterEqual(robustness_score, 0.0)
        self.assertLessEqual(robustness_score, 1.0)
        # Should be less than 1.0 due to performance drop
        self.assertLess(robustness_score, 1.0)
    
    def test_calculate_attack_success_rate(self):
        """Test calculating attack success rate."""
        # Mock test data
        test_data = {
            "total_attacks": 100,
            "successful_attacks": 30,
            "attack_types": ["fgsm", "pgd", "cw"],
            "target_classes": ["class1", "class2", "class3"]
        }
        
        attack_success_rate = self.adversarial_metrics.calculate_attack_success_rate(test_data)
        
        self.assertIsNotNone(attack_success_rate)
        self.assertGreaterEqual(attack_success_rate, 0.0)
        self.assertLessEqual(attack_success_rate, 1.0)
        self.assertEqual(attack_success_rate, 0.3)  # 30 successful out of 100 attacks
    
    def test_calculate_defense_effectiveness(self):
        """Test calculating defense effectiveness."""
        # Mock test data
        test_data = {
            "attacks_without_defense": {"success_rate": 0.8},
            "attacks_with_defense": {"success_rate": 0.2},
            "defense_types": ["adversarial_training", "feature_squeezing", "gradient_masking"],
            "performance_overhead": 0.1
        }
        
        defense_effectiveness = self.adversarial_metrics.calculate_defense_effectiveness(test_data)
        
        self.assertIsNotNone(defense_effectiveness)
        self.assertGreaterEqual(defense_effectiveness, 0.0)
        self.assertLessEqual(defense_effectiveness, 1.0)
        # Should be high since defense reduced success rate from 0.8 to 0.2
        self.assertGreater(defense_effectiveness, 0.5)
    
    def test_calculate_adversarial_transferability(self):
        """Test calculating adversarial transferability."""
        # Mock test data
        test_data = {
            "source_model_success_rate": 0.9,
            "target_model_success_rate": 0.6,
            "attack_types": ["fgsm", "pgd", "cw"],
            "model_pairs": [("model1", "model2"), ("model1", "model3")]
        }
        
        transferability = self.adversarial_metrics.calculate_adversarial_transferability(test_data)
        
        self.assertIsNotNone(transferability)
        self.assertGreaterEqual(transferability, 0.0)
        self.assertLessEqual(transferability, 1.0)
        # Should be less than 1.0 due to success rate drop
        self.assertLess(transferability, 1.0)
    
    def test_generate_adversarial_report(self):
        """Test generating adversarial report."""
        # Mock test data
        test_data = {
            "normal_performance": 0.9,
            "adversarial_performance": 0.7,
            "perturbation_types": ["noise", "occlusion", "adversarial_examples"],
            "perturbation_magnitudes": [0.1, 0.2, 0.3],
            "total_attacks": 100,
            "successful_attacks": 30,
            "attack_types": ["fgsm", "pgd", "cw"],
            "target_classes": ["class1", "class2", "class3"],
            "attacks_without_defense": {"success_rate": 0.8},
            "attacks_with_defense": {"success_rate": 0.2},
            "defense_types": ["adversarial_training", "feature_squeezing", "gradient_masking"],
            "performance_overhead": 0.1,
            "source_model_success_rate": 0.9,
            "target_model_success_rate": 0.6,
            "model_pairs": [("model1", "model2"), ("model1", "model3")]
        }
        
        report = self.adversarial_metrics.generate_adversarial_report(test_data)
        
        self.assertIsNotNone(report)
        self.assertIn("robustness_score", report)
        self.assertIn("attack_success_rate", report)
        self.assertIn("defense_effectiveness", report)
        self.assertIn("adversarial_transferability", report)


class TestCognitiveMetrics(unittest.TestCase):
    """Test suite for the CognitiveMetrics class."""
    
    def setUp(self):
        """Set up test fixtures before each test method."""
        self.cognitive_metrics = CognitiveMetrics()
    
    def test_cognitive_metrics_initialization(self):
        """Test that the cognitive metrics initialize correctly."""
        self.assertIsNotNone(self.cognitive_metrics)
        self.assertEqual(len(self.cognitive_metrics._metrics), 0)
    
    def test_calculate_reasoning_score(self):
        """Test calculating reasoning score."""
        # Mock test data
        test_data = {
            "logical_consistency": 0.8,
            "causal_inference": 0.7,
            "decision_quality": 0.9,
            "problem_solving_efficiency": 0.75
        }
        
        reasoning_score = self.cognitive_metrics.calculate_reasoning_score(test_data)
        
        self.assertIsNotNone(reasoning_score)
        self.assertGreaterEqual(reasoning_score, 0.0)
        self.assertLessEqual(reasoning_score, 1.0)
    
    def test_calculate_planning_score(self):
        """Test calculating planning score."""
        # Mock test data
        test_data = {
            "goal_decomposition": 0.8,
            "resource_allocation": 0.7,
            "timeline_estimation": 0.9,
            "contingency_planning": 0.75
        }
        
        planning_score = self.cognitive_metrics.calculate_planning_score(test_data)
        
        self.assertIsNotNone(planning_score)
        self.assertGreaterEqual(planning_score, 0.0)
        self.assertLessEqual(planning_score, 1.0)
    
    def test_calculate_learning_score(self):
        """Test calculating learning score."""
        # Mock test data
        test_data = {
            "knowledge_acquisition": 0.8,
            "skill_development": 0.7,
            "adaptation_speed": 0.9,
            "knowledge_retention": 0.75
        }
        
        learning_score = self.cognitive_metrics.calculate_learning_score(test_data)
        
        self.assertIsNotNone(learning_score)
        self.assertGreaterEqual(learning_score, 0.0)
        self.assertLessEqual(learning_score, 1.0)
    
    def test_calculate_memory_score(self):
        """Test calculating memory score."""
        # Mock test data
        test_data = {
            "short_term_memory": 0.8,
            "long_term_memory": 0.7,
            "working_memory": 0.9,
            "episodic_memory": 0.75
        }
        
        memory_score = self.cognitive_metrics.calculate_memory_score(test_data)
        
        self.assertIsNotNone(memory_score)
        self.assertGreaterEqual(memory_score, 0.0)
        self.assertLessEqual(memory_score, 1.0)
    
    def test_calculate_attention_score(self):
        """Test calculating attention score."""
        # Mock test data
        test_data = {
            "selective_attention": 0.8,
            "sustained_attention": 0.7,
            "divided_attention": 0.9,
            "attention_switching": 0.75
        }
        
        attention_score = self.cognitive_metrics.calculate_attention_score(test_data)
        
        self.assertIsNotNone(attention_score)
        self.assertGreaterEqual(attention_score, 0.0)
        self.assertLessEqual(attention_score, 1.0)
    
    def test_generate_cognitive_report(self):
        """Test generating cognitive report."""
        # Mock test data
        test_data = {
            "logical_consistency": 0.8,
            "causal_inference": 0.7,
            "decision_quality": 0.9,
            "problem_solving_efficiency": 0.75,
            "goal_decomposition": 0.8,
            "resource_allocation": 0.7,
            "timeline_estimation": 0.9,
            "contingency_planning": 0.75,
            "knowledge_acquisition": 0.8,
            "skill_development": 0.7,
            "adaptation_speed": 0.9,
            "knowledge_retention": 0.75,
            "short_term_memory": 0.8,
            "long_term_memory": 0.7,
            "working_memory": 0.9,
            "episodic_memory": 0.75,
            "selective_attention": 0.8,
            "sustained_attention": 0.7,
            "divided_attention": 0.9,
            "attention_switching": 0.75
        }
        
        report = self.cognitive_metrics.generate_cognitive_report(test_data)
        
        self.assertIsNotNone(report)
        self.assertIn("reasoning_score", report)
        self.assertIn("planning_score", report)
        self.assertIn("learning_score", report)
        self.assertIn("memory_score", report)
        self.assertIn("attention_score", report)


class TestCostMetrics(unittest.TestCase):
    """Test suite for the CostMetrics class."""
    
    def setUp(self):
        """Set up test fixtures before each test method."""
        self.cost_metrics = CostMetrics()
    
    def test_cost_metrics_initialization(self):
        """Test that the cost metrics initialize correctly."""
        self.assertIsNotNone(self.cost_metrics)
        self.assertEqual(len(self.cost_metrics._metrics), 0)
    
    def test_calculate_total_cost(self):
        """Test calculating total cost."""
        # Mock test data
        test_data = {
            "compute_cost": 100.0,
            "storage_cost": 50.0,
            "network_cost": 25.0,
            "api_cost": 75.0,
            "labor_cost": 200.0
        }
        
        total_cost = self.cost_metrics.calculate_total_cost(test_data)
        
        self.assertIsNotNone(total_cost)
        self.assertEqual(total_cost, 450.0)  # Sum of all costs
    
    def test_calculate_cost_per_unit(self):
        """Test calculating cost per unit."""
        # Mock test data
        test_data = {
            "total_cost": 450.0,
            "units_produced": 1000,
            "units_sold": 900
        }
        
        cost_per_unit = self.cost_metrics.calculate_cost_per_unit(test_data)
        
        self.assertIsNotNone(cost_per_unit)
        self.assertEqual(cost_per_unit, 0.5)  # 450 / 900
    
    def test_calculate_cost_efficiency(self):
        """Test calculating cost efficiency."""
        # Mock test data
        test_data = {
            "total_cost": 450.0,
            "revenue": 900.0,
            "output": 1000
        }
        
        cost_efficiency = self.cost_metrics.calculate_cost_efficiency(test_data)
        
        self.assertIsNotNone(cost_efficiency)
        self.assertEqual(cost_efficiency, 2.0)  # 900 / 450
    
    def test_calculate_cost_variance(self):
        """Test calculating cost variance."""
        # Mock test data
        test_data = {
            "actual_cost": 450.0,
            "budgeted_cost": 400.0
        }
        
        cost_variance = self.cost_metrics.calculate_cost_variance(test_data)
        
        self.assertIsNotNone(cost_variance)
        self.assertEqual(cost_variance, 50.0)  # 450 - 400
    
    def test_calculate_cost_savings(self):
        """Test calculating cost savings."""
        # Mock test data
        test_data = {
            "original_cost": 500.0,
            "optimized_cost": 450.0
        }
        
        cost_savings = self.cost_metrics.calculate_cost_savings(test_data)
        
        self.assertIsNotNone(cost_savings)
        self.assertEqual(cost_savings, 50.0)  # 500 - 450
    
    def test_generate_cost_report(self):
        """Test generating cost report."""
        # Mock test data
        test_data = {
            "compute_cost": 100.0,
            "storage_cost": 50.0,
            "network_cost": 25.0,
            "api_cost": 75.0,
            "labor_cost": 200.0,
            "units_produced": 1000,
            "units_sold": 900,
            "revenue": 900.0,
            "budgeted_cost": 400.0,
            "original_cost": 500.0
        }
        
        report = self.cost_metrics.generate_cost_report(test_data)
        
        self.assertIsNotNone(report)
        self.assertIn("total_cost", report)
        self.assertIn("cost_per_unit", report)
        self.assertIn("cost_efficiency", report)
        self.assertIn("cost_variance", report)
        self.assertIn("cost_savings", report)


class TestFinanceMetrics(unittest.TestCase):
    """Test suite for the FinanceMetrics class."""
    
    def setUp(self):
        """Set up test fixtures before each test method."""
        self.finance_metrics = FinanceMetrics()
    
    def test_finance_metrics_initialization(self):
        """Test that the finance metrics initialize correctly."""
        self.assertIsNotNone(self.finance_metrics)
        self.assertEqual(len(self.finance_metrics._metrics), 0)
    
    def test_calculate_profit_margin(self):
        """Test calculating profit margin."""
        # Mock test data
        test_data = {
            "revenue": 1000.0,
            "cost": 600.0
        }
        
        profit_margin = self.finance_metrics.calculate_profit_margin(test_data)
        
        self.assertIsNotNone(profit_margin)
        self.assertEqual(profit_margin, 0.4)  # (1000 - 600) / 1000
    
    def test_calculate_return_on_investment(self):
        """Test calculating return on investment."""
        # Mock test data
        test_data = {
            "gain": 500.0,
            "cost": 1000.0
        }
        
        roi = self.finance_metrics.calculate_return_on_investment(test_data)
        
        self.assertIsNotNone(roi)
        self.assertEqual(roi, 0.5)  # 500 / 1000
    
    def test_calculate_break_even_point(self):
        """Test calculating break-even point."""
        # Mock test data
        test_data = {
            "fixed_costs": 1000.0,
            "price_per_unit": 10.0,
            "variable_cost_per_unit": 6.0
        }
        
        break_even = self.finance_metrics.calculate_break_even_point(test_data)
        
        self.assertIsNotNone(break_even)
        self.assertEqual(break_even, 250.0)  # 1000 / (10 - 6)
    
    def test_calculate_cash_flow(self):
        """Test calculating cash flow."""
        # Mock test data
        test_data = {
            "cash_inflows": 1500.0,
            "cash_outflows": 1000.0
        }
        
        cash_flow = self.finance_metrics.calculate_cash_flow(test_data)
        
        self.assertIsNotNone(cash_flow)
        self.assertEqual(cash_flow, 500.0)  # 1500 - 1000
    
    def test_calculate_working_capital(self):
        """Test calculating working capital."""
        # Mock test data
        test_data = {
            "current_assets": 2000.0,
            "current_liabilities": 1000.0
        }
        
        working_capital = self.finance_metrics.calculate_working_capital(test_data)
        
        self.assertIsNotNone(working_capital)
        self.assertEqual(working_capital, 1000.0)  # 2000 - 1000
    
    def test_generate_finance_report(self):
        """Test generating finance report."""
        # Mock test data
        test_data = {
            "revenue": 1000.0,
            "cost": 600.0,
            "gain": 500.0,
            "investment": 1000.0,
            "fixed_costs": 1000.0,
            "price_per_unit": 10.0,
            "variable_cost_per_unit": 6.0,
            "cash_inflows": 1500.0,
            "cash_outflows": 1000.0,
            "current_assets": 2000.0,
            "current_liabilities": 1000.0
        }
        
        report = self.finance_metrics.generate_finance_report(test_data)
        
        self.assertIsNotNone(report)
        self.assertIn("profit_margin", report)
        self.assertIn("return_on_investment", report)
        self.assertIn("break_even_point", report)
        self.assertIn("cash_flow", report)
        self.assertIn("working_capital", report)


class TestMarketingMetrics(unittest.TestCase):
    """Test suite for the MarketingMetrics class."""
    
    def setUp(self):
        """Set up test fixtures before each test method."""
        self.marketing_metrics = MarketingMetrics()
    
    def test_marketing_metrics_initialization(self):
        """Test that the marketing metrics initialize correctly."""
        self.assertIsNotNone(self.marketing_metrics)
        self.assertEqual(len(self.marketing_metrics._metrics), 0)
    
    def test_calculate_conversion_rate(self):
        """Test calculating conversion rate."""
        # Mock test data
        test_data = {
            "conversions": 50,
            "visitors": 1000
        }
        
        conversion_rate = self.marketing_metrics.calculate_conversion_rate(test_data)
        
        self.assertIsNotNone(conversion_rate)
        self.assertEqual(conversion_rate, 0.05)  # 50 / 1000
    
    def test_calculate_customer_acquisition_cost(self):
        """Test calculating customer acquisition cost."""
        # Mock test data
        test_data = {
            "marketing_cost": 5000.0,
            "new_customers": 100
        }
        
        cac = self.marketing_metrics.calculate_customer_acquisition_cost(test_data)
        
        self.assertIsNotNone(cac)
        self.assertEqual(cac, 50.0)  # 5000 / 100
    
    def test_calculate_customer_lifetime_value(self):
        """Test calculating customer lifetime value."""
        # Mock test data
        test_data = {
            "average_purchase_value": 100.0,
            "purchase_frequency": 5,
            "customer_lifespan": 2  # years
        }
        
        clv = self.marketing_metrics.calculate_customer_lifetime_value(test_data)
        
        self.assertIsNotNone(clv)
        self.assertEqual(clv, 1000.0)  # 100 * 5 * 2
    
    def test_calculate_return_on_ad_spend(self):
        """Test calculating return on ad spend."""
        # Mock test data
        test_data = {
            "revenue": 10000.0,
            "ad_spend": 2000.0
        }
        
        roas = self.marketing_metrics.calculate_return_on_ad_spend(test_data)
        
        self.assertIsNotNone(roas)
        self.assertEqual(roas, 5.0)  # 10000 / 2000
    
    def test_calculate_market_share(self):
        """Test calculating market share."""
        # Mock test data
        test_data = {
            "company_sales": 5000.0,
            "total_market_sales": 25000.0
        }
        
        market_share = self.marketing_metrics.calculate_market_share(test_data)
        
        self.assertIsNotNone(market_share)
        self.assertEqual(market_share, 0.2)  # 5000 / 25000
    
    def test_generate_marketing_report(self):
        """Test generating marketing report."""
        # Mock test data
        test_data = {
            "conversions": 50,
            "visitors": 1000,
            "marketing_cost": 5000.0,
            "new_customers": 100,
            "average_purchase_value": 100.0,
            "purchase_frequency": 5,
            "customer_lifespan": 2,
            "revenue": 10000.0,
            "ad_spend": 2000.0,
            "company_sales": 5000.0,
            "total_market_sales": 25000.0
        }
        
        report = self.marketing_metrics.generate_marketing_report(test_data)
        
        self.assertIsNotNone(report)
        self.assertIn("conversion_rate", report)
        self.assertIn("customer_acquisition_cost", report)
        self.assertIn("customer_lifetime_value", report)
        self.assertIn("return_on_ad_spend", report)
        self.assertIn("market_share", report)


class TestOperationsMetrics(unittest.TestCase):
    """Test suite for the OperationsMetrics class."""
    
    def setUp(self):
        """Set up test fixtures before each test method."""
        self.operations_metrics = OperationsMetrics()
    
    def test_operations_metrics_initialization(self):
        """Test that the operations metrics initialize correctly."""
        self.assertIsNotNone(self.operations_metrics)
        self.assertEqual(len(self.operations_metrics._metrics), 0)
    
    def test_calculate_throughput(self):
        """Test calculating throughput."""
        # Mock test data
        test_data = {
            "units_produced": 1000,
            "time_period": 8  # hours
        }
        
        throughput = self.operations_metrics.calculate_throughput(test_data)
        
        self.assertIsNotNone(throughput)
        self.assertEqual(throughput, 125.0)  # 1000 / 8
    
    def test_calculate_cycle_time(self):
        """Test calculating cycle time."""
        # Mock test data
        test_data = {
            "total_production_time": 480,  # minutes
            "units_produced": 100
        }
        
        cycle_time = self.operations_metrics.calculate_cycle_time(test_data)
        
        self.assertIsNotNone(cycle_time)
        self.assertEqual(cycle_time, 4.8)  # 480 / 100
    
    def test_calculate_utilization_rate(self):
        """Test calculating utilization rate."""
        # Mock test data
        test_data = {
            "actual_output": 800,
            "maximum_capacity": 1000
        }
        
        utilization_rate = self.operations_metrics.calculate_utilization_rate(test_data)
        
        self.assertIsNotNone(utilization_rate)
        self.assertEqual(utilization_rate, 0.8)  # 800 / 1000
    
    def test_calculate_defect_rate(self):
        """Test calculating defect rate."""
        # Mock test data
        test_data = {
            "defective_units": 20,
            "total_units": 1000
        }
        
        defect_rate = self.operations_metrics.calculate_defect_rate(test_data)
        
        self.assertIsNotNone(defect_rate)
        self.assertEqual(defect_rate, 0.02)  # 20 / 1000
    
    def test_calculate_overall_equipment_effectiveness(self):
        """Test calculating overall equipment effectiveness."""
        # Mock test data
        test_data = {
            "availability": 0.9,
            "performance": 0.8,
            "quality": 0.95
        }
        
        oee = self.operations_metrics.calculate_overall_equipment_effectiveness(test_data)
        
        self.assertIsNotNone(oee)
        self.assertEqual(oee, 0.684)  # 0.9 * 0.8 * 0.95
    
    def test_generate_operations_report(self):
        """Test generating operations report."""
        # Mock test data
        test_data = {
            "units_produced": 1000,
            "time_period": 8,
            "total_production_time": 480,
            "actual_output": 800,
            "maximum_capacity": 1000,
            "defective_units": 20,
            "total_units": 1000,
            "availability": 0.9,
            "performance": 0.8,
            "quality": 0.95
        }
        
        report = self.operations_metrics.generate_operations_report(test_data)
        
        self.assertIsNotNone(report)
        self.assertIn("throughput", report)
        self.assertIn("cycle_time", report)
        self.assertIn("utilization_rate", report)
        self.assertIn("defect_rate", report)
        self.assertIn("overall_equipment_effectiveness", report)


class TestStressMetrics(unittest.TestCase):
    """Test suite for the StressMetrics class."""
    
    def setUp(self):
        """Set up test fixtures before each test method."""
        self.stress_metrics = StressMetrics()
    
    def test_stress_metrics_initialization(self):
        """Test that the stress metrics initialize correctly."""
        self.assertIsNotNone(self.stress_metrics)
        self.assertEqual(len(self.stress_metrics._metrics), 0)
    
    def test_calculate_system_throughput_under_stress(self):
        """Test calculating system throughput under stress."""
        # Mock test data
        test_data = {
            "requests_processed": 5000,
            "stress_duration": 300,  # seconds
            "concurrent_users": 1000
        }
        
        throughput = self.stress_metrics.calculate_system_throughput_under_stress(test_data)
        
        self.assertIsNotNone(throughput)
        self.assertEqual(throughput, 16.67)  # 5000 / 300 (approximately)
    
    def test_calculate_response_time_degradation(self):
        """Test calculating response time degradation."""
        # Mock test data
        test_data = {
            "normal_response_time": 100,  # ms
            "stress_response_time": 500  # ms
        }
        
        degradation = self.stress_metrics.calculate_response_time_degradation(test_data)
        
        self.assertIsNotNone(degradation)
        self.assertEqual(degradation, 4.0)  # 500 / 100
    
    def test_calculate_error_rate_under_stress(self):
        """Test calculating error rate under stress."""
        # Mock test data
        test_data = {
            "error_count": 50,
            "total_requests": 1000
        }
        
        error_rate = self.stress_metrics.calculate_error_rate_under_stress(test_data)
        
        self.assertIsNotNone(error_rate)
        self.assertEqual(error_rate, 0.05)  # 50 / 1000
    
    def test_calculate_resource_utilization(self):
        """Test calculating resource utilization."""
        # Mock test data
        test_data = {
            "cpu_usage": 80,  # percent
            "memory_usage": 70,  # percent
            "disk_usage": 60,  # percent
            "network_usage": 50  # percent
        }
        
        utilization = self.stress_metrics.calculate_resource_utilization(test_data)
        
        self.assertIsNotNone(utilization)
        self.assertEqual(utilization, 65.0)  # (80 + 70 + 60 + 50) / 4
    
    def test_calculate_bottleneck_severity(self):
        """Test calculating bottleneck severity."""
        # Mock test data
        test_data = {
            "cpu_utilization": 90,
            "memory_utilization": 70,
            "disk_utilization": 60,
            "network_utilization": 50
        }
        
        severity = self.stress_metrics.calculate_bottleneck_severity(test_data)
        
        self.assertIsNotNone(severity)
        self.assertGreaterEqual(severity, 0.0)
        self.assertLessEqual(severity, 1.0)
        # Should be high due to high CPU utilization
        self.assertGreater(severity, 0.5)
    
    def test_generate_stress_report(self):
        """Test generating stress report."""
        # Mock test data
        test_data = {
            "requests_processed": 5000,
            "stress_duration": 300,
            "concurrent_users": 1000,
            "normal_response_time": 100,
            "stress_response_time": 500,
            "error_count": 50,
            "total_requests": 1000,
            "cpu_usage": 80,
            "memory_usage": 70,
            "disk_usage": 60,
            "network_usage": 50,
            "cpu_utilization": 90,
            "memory_utilization": 70,
            "disk_utilization": 60,
            "network_utilization": 50
        }
        
        report = self.stress_metrics.generate_stress_report(test_data)
        
        self.assertIsNotNone(report)
        self.assertIn("system_throughput_under_stress", report)
        self.assertIn("response_time_degradation", report)
        self.assertIn("error_rate_under_stress", report)
        self.assertIn("resource_utilization", report)
        self.assertIn("bottleneck_severity", report)


class TestTrustMetrics(unittest.TestCase):
    """Test suite for the TrustMetrics class."""
    
    def setUp(self):
        """Set up test fixtures before each test method."""
        self.trust_metrics = TrustMetrics()
    
    def test_trust_metrics_initialization(self):
        """Test that the trust metrics initialize correctly."""
        self.assertIsNotNone(self.trust_metrics)
        self.assertEqual(len(self.trust_metrics._metrics), 0)
    
    def test_calculate_reliability_score(self):
        """Test calculating reliability score."""
        # Mock test data
        test_data = {
            "uptime": 99.9,  # percent
            "mean_time_between_failures": 1000,  # hours
            "mean_time_to_repair": 4  # hours
        }
        
        reliability = self.trust_metrics.calculate_reliability_score(test_data)
        
        self.assertIsNotNone(reliability)
        self.assertGreaterEqual(reliability, 0.0)
        self.assertLessEqual(reliability, 1.0)
    
    def test_calculate_transparency_score(self):
        """Test calculating transparency score."""
        # Mock test data
        test_data = {
            "decision_explanations": 0.9,
            "data_provenance": 0.8,
            "model_documentation": 0.95,
            "audit_trail": 0.85
        }
        
        transparency = self.trust_metrics.calculate_transparency_score(test_data)
        
        self.assertIsNotNone(transparency)
        self.assertGreaterEqual(transparency, 0.0)
        self.assertLessEqual(transparency, 1.0)
    
    def test_calculate_fairness_score(self):
        """Test calculating fairness score."""
        # Mock test data
        test_data = {
            "demographic_parity": 0.9,
            "equal_opportunity": 0.85,
            "equalized_odds": 0.8,
            "individual_fairness": 0.75
        }
        
        fairness = self.trust_metrics.calculate_fairness_score(test_data)
        
        self.assertIsNotNone(fairness)
        self.assertGreaterEqual(fairness, 0.0)
        self.assertLessEqual(fairness, 1.0)
    
    def test_calculate_accountability_score(self):
        """Test calculating accountability score."""
        # Mock test data
        test_data = {
            "error_detection": 0.9,
            "error_correction": 0.85,
            "responsibility_assignment": 0.8,
            "redress_mechanisms": 0.75
        }
        
        accountability = self.trust_metrics.calculate_accountability_score(test_data)
        
        self.assertIsNotNone(accountability)
        self.assertGreaterEqual(accountability, 0.0)
        self.assertLessEqual(accountability, 1.0)
    
    def test_calculate_security_score(self):
        """Test calculating security score."""
        # Mock test data
        test_data = {
            "vulnerability_assessment": 0.9,
            "penetration_testing": 0.85,
            "access_controls": 0.95,
            "data_encryption": 0.9
        }
        
        security = self.trust_metrics.calculate_security_score(test_data)
        
        self.assertIsNotNone(security)
        self.assertGreaterEqual(security, 0.0)
        self.assertLessEqual(security, 1.0)
    
    def test_generate_trust_report(self):
        """Test generating trust report."""
        # Mock test data
        test_data = {
            "uptime": 99.9,
            "mean_time_between_failures": 1000,
            "mean_time_to_repair": 4,
            "decision_explanations": 0.9,
            "data_provenance": 0.8,
            "model_documentation": 0.95,
            "audit_trail": 0.85,
            "demographic_parity": 0.9,
            "equal_opportunity": 0.85,
            "equalized_odds": 0.8,
            "individual_fairness": 0.75,
            "error_detection": 0.9,
            "error_correction": 0.85,
            "responsibility_assignment": 0.8,
            "redress_mechanisms": 0.75,
            "vulnerability_assessment": 0.9,
            "penetration_testing": 0.85,
            "access_controls": 0.95,
            "data_encryption": 0.9
        }
        
        report = self.trust_metrics.generate_trust_report(test_data)
        
        self.assertIsNotNone(report)
        self.assertIn("reliability_score", report)
        self.assertIn("transparency_score", report)
        self.assertIn("fairness_score", report)
        self.assertIn("accountability_score", report)
        self.assertIn("security_score", report)


class TestMetricSuite(unittest.TestCase):
    """Test suite for the MetricSuite class."""
    
    def setUp(self):
        """Set up test fixtures before each test method."""
        self.metric_suite = MetricSuite()
    
    def test_metric_suite_initialization(self):
        """Test that the metric suite initializes correctly."""
        self.assertIsNotNone(self.metric_suite)
        self.assertEqual(len(self.metric_suite._metrics), 0)
    
    def test_register_metric(self):
        """Test registering a metric."""
        metric = {
            "name": "test_metric",
            "description": "A test metric",
            "calculation_function": lambda x: x * 2,
            "category": "test"
        }
        
        metric_id = self.metric_suite.register_metric(metric)
        
        self.assertIsNotNone(metric_id)
        self.assertIn(metric_id, self.metric_suite._metrics)
        self.assertEqual(self.metric_suite._metrics[metric_id]["name"], "test_metric")
    
    def test_calculate_metric(self):
        """Test calculating a metric."""
        metric = {
            "name": "test_metric",
            "description": "A test metric",
            "calculation_function": lambda x: x * 2,
            "category": "test"
        }
        
        metric_id = self.metric_suite.register_metric(metric)
        
        result = self.metric_suite.calculate_metric(metric_id, 5)
        
        self.assertEqual(result, 10)  # 5 * 2
    
    def test_calculate_metrics_by_category(self):
        """Test calculating metrics by category."""
        metric1 = {
            "name": "test_metric1",
            "description": "A test metric",
            "calculation_function": lambda x: x * 2,
            "category": "test"
        }
        
        metric2 = {
            "name": "test_metric2",
            "description": "Another test metric",
            "calculation_function": lambda x: x + 3,
            "category": "test"
        }
        
        metric3 = {
            "name": "other_metric",
            "description": "A metric in another category",
            "calculation_function": lambda x: x - 1,
            "category": "other"
        }
        
        metric1_id = self.metric_suite.register_metric(metric1)
        metric2_id = self.metric_suite.register_metric(metric2)
        metric3_id = self.metric_suite.register_metric(metric3)
        
        results = self.metric_suite.calculate_metrics_by_category("test", 5)
        
        self.assertEqual(len(results), 2)
        self.assertIn(metric1_id, results)
        self.assertIn(metric2_id, results)
        self.assertEqual(results[metric1_id], 10)  # 5 * 2
        self.assertEqual(results[metric2_id], 8)   # 5 + 3
    
    def test_generate_comprehensive_report(self):
        """Test generating a comprehensive report."""
        metric1 = {
            "name": "test_metric1",
            "description": "A test metric",
            "calculation_function": lambda x: x * 2,
            "category": "test"
        }
        
        metric2 = {
            "name": "test_metric2",
            "description": "Another test metric",
            "calculation_function": lambda x: x + 3,
            "category": "test"
        }
        
        metric3 = {
            "name": "other_metric",
            "description": "A metric in another category",
            "calculation_function": lambda x: x - 1,
            "category": "other"
        }
        
        self.metric_suite.register_metric(metric1)
        self.metric_suite.register_metric(metric2)
        self.metric_suite.register_metric(metric3)
        
        report = self.metric_suite.generate_comprehensive_report(5)
        
        self.assertIsNotNone(report)
        self.assertIn("test", report)
        self.assertIn("other", report)
        self.assertEqual(len(report["test"]), 2)
        self.assertEqual(len(report["other"]), 1)
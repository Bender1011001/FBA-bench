from abc import ABC, abstractmethod
from typing import Dict, Any, Optional

class BaseLLMClient(ABC):
    """
    Abstract Base Class for LLM clients integrating with FBA-Bench.
    All LLM client implementations (e.g., OpenAI, OpenRouter, local models)
    must adhere to this interface.
    """

    def __init__(self, model_name: str, api_key: Optional[str] = None, base_url: Optional[str] = None):
        self.model_name = model_name
        self.api_key = api_key
        self.base_url = base_url

    @abstractmethod
    async def generate_response(self, prompt: str, **kwargs) -> Dict[str, Any]:
        """
        Generates a structured response from the LLM based on the given prompt.

        Args:
            prompt: The formatted prompt string generated by the PromptAdapter.
            **kwargs: Additional parameters for the LLM API call (e.g., temperature, max_tokens).

        Returns:
            A dictionary containing the LLM's raw response. Expected to have a "choices" field
            similar to OpenAI's API.
            Example: {"choices": [{"message": {"content": "..."}}], "usage": {"prompt_tokens": 100, "completion_tokens": 50}}
        
        Raises:
            LLMClientError: If there is an issue communicating with the LLM API or receiving a valid response.
        """
        pass

    @abstractmethod
    async def get_token_count(self, text: str) -> int:
        """
        Estimates or calculates the token count for a given text using the client's model.

        Args:
            text: The text string to count tokens for.

        Returns:
            The number of tokens.
        """
        pass

class LLMClientError(Exception):
    """Custom exception for LLM client-related errors."""
    def __init__(self, message: str, original_exception: Optional[Exception] = None, status_code: Optional[int] = None):
        super().__init__(message)
        self.original_exception = original_exception
        self.status_code = status_code

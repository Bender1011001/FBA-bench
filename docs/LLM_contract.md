# FBA-Bench LLM Agent Interface Contract

This document specifies the standardized interface and interaction protocols for external LLM (Large Language Model) agents to integrate with FBA-Bench. By adhering to this contract, any policy-tuned LLM can be seamlessly plugged into the benchmark for evaluation.

## 1. Core Principles

- **Simplicity**: Easy for any team to implement with minimal overhead.
- **Consistency**: Same format and interaction model across all simulation tiers and scenarios.
- **Debuggability**: Clear error messages and validation feedback to facilitate agent development.
- **Extensibility**: Designed to easily accommodate new action types and state information as the simulation evolves.
- **Performance**: Minimizes prompt overhead for efficient token usage and faster simulation runs.

## 2. LLM Interface Contract Specification

LLM agents interact with FBA-Bench via a request-response cycle.

### 2.1. Input Format (Prompt Structure)

The simulation state, recent events, and available actions are presented to the LLM as a structured text prompt. This prompt is generated by the `llm_interface.prompt_adapter.PromptAdapter` module.

```
=== FBA SIMULATION STATE ===
Tick: [Current simulation tick] | Day: [Current simulation day] | Time: [Current simulation time UTC]

BUDGET STATUS:
- Tokens used this turn: [Current tick tokens] / [Max tokens per turn] ([Percentage]%)
- Total simulation tokens: [Total simulation tokens] / [Max total simulation tokens] ([Percentage]%)
- Estimated cost this turn: $[Cost this turn] (at current token costs)
- Estimated total cost: $[Total cost] (at current token costs)
- Budget health: [HEALTHY|WARNING|CRITICAL]

PRODUCT PORTFOLIO:
{
  "ASIN1": {
    "current_price": [float],
    "inventory": [int],
    "cost_basis": [float],
    "sales_velocity": [float, optional],
    "competitor_prices": [[float], optional]
  },
  "ASIN2": { ... }
}

RECENT EVENTS:
- [Formatted Event Summary 1]
- [Formatted Event Summary 2]
...
(e.g., - SaleOccurred at 14:30: ASIN B07XAMPLE sold 3 units at 24.99.)
(e.g., - CompetitorPricesUpdated at 14:31: Competitor prices updated (C001 @ 22.95, C002 @ 26.50).)
(e.g., - BUDGET WARNING at 14:35: Per-tick token limit nearing/exceeded... SIMULATION MAY TERMINATE.)

SCENARIO CONTEXT:
[Optional: Human-readable context about the current tier, market shocks, or specific goals for the scenario.]

AVAILABLE ACTIONS:
- action_type_1: Description of action 1 (Parameters: {param1: type, param2: type})
- action_type_2: Description of action 2 (Parameters: {param1: type, param2: type})
...
(e.g., - set_price: Adjust product pricing (Parameters: {asin: str, price: float}))
(e.g., - wait_next_day: No action this turn)

REQUIRED OUTPUT FORMAT:
{
  "actions": [{"type": "action_name", "parameters": {"key": "value"}}],
  "reasoning": "Your decision rationale",
  "confidence": 0.0-1.0
}

---
Your response MUST be a single JSON object conforming strictly to the 'REQUIRED OUTPUT FORMAT'. Do NOT include any other text or formatting outside the JSON.
[Additional instructions based on template for the scenario: e.g., "Analyze the initial market conditions..." or "Critically evaluate the market shock..."]
```

### 2.2. Output Format (JSON Schema)

The LLM agent **must** respond with a single JSON object that strictly adheres to the following schema. This ensures parsing without complex text parsing and enables robust validation.

**Main Response Schema (`LLM_RESPONSE_SCHEMA`)**:

```json
{
  "$schema": "http://json-schema.org/draft-07/schema#",
  "type": "object",
  "properties": {
    "actions": {
      "type": "array",
      "items": {
        "type": "object",
        "properties": {
          "type": { "type": "string" },
          "asin": { "type": "string" },
          "price": { "type": "number" }
        },
        "required": ["type"]
      },
      "minItems": 1,
      "description": "List of actions the agent wishes to perform in this simulation tick."
    },
    "reasoning": {
      "type": "string",
      "description": "Brief explanation or rationale for the agent's decision(s)."
    },
    "confidence": {
      "type": "number",
      "minimum": 0.0,
      "maximum": 1.0,
      "description": "Agent's confidence in its combined decision(s) for this turn (0.0-1.0)."
    }
  },
  "required": ["actions", "reasoning", "confidence"],
  "additionalProperties": false
}
```

**Specific Action Schemas (`ACTION_SCHEMAS`)**:

Each action type within the `actions` array has its own specific schema:

-   **`set_price` Action**: Adjusts the price of a product.
    ```json
    {
      "type": "object",
      "properties": {
        "type": { "type": "string", "enum": ["set_price"] },
        "asin": { "type": "string", "pattern": "^B0[0-9A-Z]{8}$" },
        "price": { "type": "number", "exclusiveMinimum": 0.0 }
      },
      "required": ["type", "asin", "price"],
      "additionalProperties": false
    }
    ```
    *`asin`*: The ASIN of the product to update (e.g., "B07XAMPLE").
    *`price`*: The new price for the product (float, e.g., 23.47). Must be greater than 0.0.

-   **`wait_next_day` Action**: Instructs the agent to take no specific action this turn, allowing the simulation to advance.
    ```json
    {
      "type": "object",
      "properties": {
        "type": { "type": "string", "enum": ["wait_next_day"] }
      },
      "required": ["type"],
      "additionalProperties": false
    }
    ```

**Example Valid Response**:

```json
{
  "actions": [
    {
      "type": "set_price",
      "asin": "B07XEXAMPLE",
      "price": 23.47
    },
    {
      "type": "wait_next_day"
    }
  ],
  "reasoning": "Lowering price to capture market share based on competitor movement, then waiting for next day's results due to limited information.",
  "confidence": 0.75
}
```

### 2.3. Model Confidence

The `confidence` field (0.0-1.0) allows the agent to signal its certainty in its decisions. This metric can be used by the benchmark beyond simple correctness, for example, in scenarios where risk-averse behavior might be preferred.

## 3. Validation and Error Handling

FBA-Bench employs a robust validation and error handling system to ensure consistency and provide clear feedback.

### 3.1. Types of Errors

1.  **JSON Parsing Errors**: The LLM response is not a valid JSON string.
2.  **Schema Violations**: The parsed JSON does not conform to the `LLM_RESPONSE_SCHEMA` or the specific `ACTION_SCHEMAS`. This includes missing required fields, incorrect data types, or invalid action types.
3.  **Business Logic Errors**: The actions, while syntactically valid by schema, are impossible or invalid within the simulation context (e.g., setting a negative price, targeting a non-existent ASIN, or attempting an action beyond allowed limits). These are validated by core simulation services like `WorldStore`.

### 3.2. Trust Score Impact & Recovery

-   **Trust Score Penalty**: Any validation error or business logic error will incur a penalty on the agent's `Trust Score`. The magnitude of the penalty depends on the severity (e.g., JSON parsing errors might be higher than a minor schema mismatch).
    -   `JSONParsingError` or `UnexpectedParsingError`: Typically a higher penalty (e.g., -0.1 to -0.15).
    -   `SchemaViolation`: A moderate penalty (e.g., -0.05).
    -   `BusinessLogicError`: A moderate penalty (e.g., -0.05).
-   **Recovery Mechanisms**:
    -   For `JSON Parsing Errors` and `Schema Violations`, the invalid actions are **rejected**, and no state changes resulting from them occur. The simulation continues, but the agent's trust score is impacted.
    -   The system provides structured error feedback, including the error type, a descriptive message, the problematic field (`path`), the invalid value, and a `suggested_fix`. This information is logged and can potentially be fed back to the LLM in a subsequent turn (depending on the agent's implementation) for self-correction.

**Example System Response to Invalid Agent Output**:

```json
{
  "error": "SchemaViolation",
  "message": "Missing required field 'price' in set_price action",
  "path": "actions/0/price",
  "invalid_value": {},
  "suggested_fix": "Include 'price' field with a numeric value (e.g., 23.47).",
  "trust_score_penalty": -0.05,
  "valid_example": {
    "type": "set_price", 
    "asin": "B07X", 
    "price": 23.47
  }
}
```

This structured feedback allows external teams to understand why an agent's response was rejected and improve their model's output formatting or decision-making.

## 4. Prompt Template System

The `llm_interface.prompt_templates.PromptTemplates` class provides standardized templates to adapt prompts for different simulation scenarios, ensuring consistency and clear guidance for the LLM.

-   **Initial Setup**: Provides full context at the start of the simulation.
    -   *Guidance*: Focus on strategy formulation based on initial market conditions.
-   **Regular Updates**: Presents incremental state changes and recent events.
    -   *Guidance*: Optimize existing strategy based on latest data.
-   **Shock Events**: Alerts the LLM to critical, sudden market changes.
    -   *Guidance*: Prioritize crisis response, mitigation, and recovery.
-   **Budget Warnings**: Notifies the LLM when token usage nears limits.
    -   *Guidance*: Encourage token-efficient reasoning and essential decisions.

## 5. Integration Specifications

### 5.1. Budget Enforcement System

-   **Module**: [`constraints.agent_gateway.AgentGateway`](constraints/agent_gateway.py:10)
-   **Mechanism**:
    -   The `AgentGateway` intercepts LLM requests and responses.
    -   It injects a `BUDGET STATUS` section into the prompt (via `BudgetEnforcer.format_budget_status_for_prompt()`).
    -   It estimates and records token usage *before* LLM calls (soft check) and commits actual usage *after* (hard check).
    -   `BudgetEnforcer` publishes `BudgetWarning` or `BudgetExceeded` events if limits are approached or crossed, triggering potential `SystemExit` for hard failures.
-   **Impact**: LLM agents are aware of and constrained by real-time token budgets, promoting efficiency. Violations directly impact agent evaluation and may terminate the simulation.

### 5.2. Metrics System for Trust Score Tracking

-   **Module**: [`metrics.trust_metrics.TrustMetrics`](metrics/trust_metrics.py:4) and potentially [`services.trust_score_service.TrustScoreService`](services/trust_score_service.py:1)
-   **Mechanism**:
    -   The `llm_interface.response_parser.LLMResponseParser` directly interacts with `TrustMetrics` (via dependency injection) to apply penalties for:
        -   JSON parsing failures
        -   Schema violations
        -   Business logic errors (if reported back to the parser, or handled directly by services)
    -   `TrustMetrics` aggregates these penalties into the overall agent trust score, which is a key evaluation metric for FBA-Bench.
-   **Impact**: Agents are incentivized to produce valid, actionable, and compliant responses.

### 5.3. Event Bus for Action Processing

-   **Module**: [`event_bus.EventBus`](event_bus.py:219)
-   **Mechanism**:
    -   Validated actions from the LLM's response are converted into corresponding [`BaseEvent`](events.py:51) command objects (e.g., `SetPriceCommand`).
    -   These command events are then `publish`ed to the central `EventBus`.
    -   Core simulation services (e.g., `WorldStore`) `subscribe` to these commands, arbitrate them, and apply state changes.
-   **Impact**: Ensures LLM actions are processed within the existing event-driven simulation flow, benefiting from its arbitration, validation, and immutability guarantees.

### 5.4. Curriculum System for Tier-Specific Prompts

-   **Module**: (Conceptual, based on `scenarios/` and `constraints/tier_configs/`)
-   **Mechanism**:
    -   The `PromptAdapter` can be configured by the curriculum system (or simulation orchestrator) to select appropriate `PromptTemplates` (e.g., `initial_setup`, `regular_update`, `shock_event`) based on the current simulation tier or scenario.
    -   Tier-specific constraints (from `constraints/tier_configs/*.yaml`) are loaded by the `BudgetEnforcer` and automatically injected into the prompt via the `AgentGateway`.
-   **Impact**: Ensures LLM agents receive appropriate context and challenges tailored to their current skill tier and scenario.

## 6. Development Guidelines for External Teams

To integrate your LLM agent, you will need to:

1.  **Implement an `BaseLLMClient`**: Create a class that inherits from `llm_interface.contract.BaseLLMClient` and implements `generate_response` method. For OpenRouter, you can use/adapt the `OpenRouterClient`.
2.  **Understand the Prompt Structure**: Ensure your LLM is fine-tuned or prompted to understand the structure of the FBA-Bench input, especially the `PRODUCT PORTFOLIO`, `RECENT EVENTS`, and `AVAILABLE ACTIONS` sections.
3.  **Strictly Adhere to Output JSON Schema**: Your LLM **must** output JSON that validates against the specified schemas. Any deviation will result in penalties.
4.  **Handle Error Feedback (Optional but Recommended)**: If your agent is capable of self-correction, parse the structured error feedback from FBA-Bench (if available in your agent's observation loop) to improve future responses.
5.  **Consider Confidence**: Encourage your LLM to provide a realistic `confidence` score for its decisions.
6.  **Manage Token Usage**: Optimize your LLM's responses to stay within budget constraints to avoid penalties and potential simulation termination.

This contract provides a clear and robust framework for integrating diverse LLM agents into FBA-Bench, fostering fair and effective benchmarking.
from __future__ import annotations

from dataclasses import dataclass
from decimal import Decimal
from typing import Optional

from money import Money
from services.toolbox_api_service import ToolboxAPIService
from services.toolbox_schemas import (
    ObserveRequest,
    SetPriceRequest,
    SetPriceResponse,
)


@dataclass(frozen=True)
class BaselineConfig:
    min_margin_pct: float = 10.0  # reserved for future extension
    max_price_change_pct: float = 20.0  # hard cap on a single decision


class BaselineAgentV1:
    """
    Minimal deterministic pricing agent.

    Policy:
    - If conversion_rate < 0.05: decrease price by up to 5% (capped by max_price_change_pct)
    - If conversion_rate > 0.2: increase price by up to 5% (capped by max_price_change_pct)
    - Else: no action

    Implementation details:
    - All price math is performed with Decimal and Money to avoid float contamination
    - Rounds to integer cents deterministically via Money's rounding
    """

    def __init__(
        self,
        agent_id: str,
        toolbox: ToolboxAPIService,
        min_margin_pct: float = 10.0,
        max_price_change_pct: float = 20.0,
    ):
        self.agent_id = agent_id
        self.toolbox = toolbox
        self.config = BaselineConfig(
            min_margin_pct=min_margin_pct, max_price_change_pct=max_price_change_pct
        )

    def decide(self, asin: str) -> Optional[SetPriceResponse]:
        obs = self.toolbox.observe(ObserveRequest(asin=asin))
        # Require an existing observation with price for this trivial policy
        if not obs.found or obs.price is None:
            return None

        current_price: Money = obs.price
        cr = obs.conversion_rate

        # Decide change direction and magnitude (desired 5%)
        if cr is not None and cr < 0.05:
            desired_change = Decimal("-0.05")
        elif cr is not None and cr > 0.2:
            desired_change = Decimal("0.05")
        else:
            return None  # no change

        # Cap change by max bound
        max_bound = Decimal(str(self.config.max_price_change_pct)) / Decimal("100")
        magnitude = min(abs(desired_change), max_bound)
        signed_change = magnitude.copy_negate() if desired_change < 0 else magnitude

        # Compute new price with deterministic rounding to cents
        factor = Decimal("1") + signed_change
        new_price = current_price * factor  # Money * Decimal is supported with ROUND_HALF_UP

        # Safety: ensure at least 1 cent
        if new_price.cents <= 0:
            new_price = Money(1, current_price.currency)

        # Avoid publishing no-op if rounding yielded same price
        if new_price == current_price:
            return None

        # Publish command via toolbox
        rsp = self.toolbox.set_price(
            SetPriceRequest(
                agent_id=self.agent_id,
                asin=asin,
                new_price=new_price,
                reason=f"baseline_v1 {'decrease' if signed_change < 0 else 'increase'} {abs(magnitude) * 100}%",
            )
        )
        return rsp

# ---------------- Rule-based baseline agent v1 (deterministic, tool-optional) ----------------
# This extends the existing pricing BaselineAgentV1 by adding a generic, rule-based API surface
# compatible with the project-wide orchestrator expectations:
# - decide(task: dict | str, context: dict | None = None) -> dict
# - decide_async(task: dict | str, context: dict | None = None) -> dict
#
# Notes:
# - The original BaselineAgentV1 pricing class and API are preserved unchanged for backward-compat.
# - No heavy dependencies introduced; stdlib only + existing project logging helper if available.


import asyncio
import json
import logging
import math
import re
import time
from collections import deque
from dataclasses import dataclass
from typing import Any, Callable, Deque, Dict, Iterable, List, Optional, Tuple, Union

try:
    # Prefer project logging setup if available
    from fba_bench.core.logging import setup_logging  # type: ignore
    setup_logging()
except Exception:
    # Fall back silently to stdlib default configuration if project logger isn't available at import time
    pass

_logger = logging.getLogger(__name__)

# ---------------- Public constants and types ----------------

RuleResult = Dict[str, Any]
ToolSpec = Dict[str, Any]
ToolsRegistry = Dict[str, Callable[..., Any]]

DEFAULT_MAX_RULE_STEPS = 6
DEFAULT_SUMMARY_LEN = 1200  # characters, conservative for tests and determinism
DEFAULT_TOKEN_RATIO = 1.3   # words * ratio ≈ tokens
DEFAULT_MEMORY_CAPACITY = 10

# Simple safety blocklist (lower-cased checks)
BLOCKLIST = {"passwords", "malware", "pii"}

# In-memory episodic memory store: session_id -> deque of interactions
_MEMORY: Dict[str, Deque[Dict[str, Any]]] = {}

# ---------------- Utility helpers ----------------

def _now_ms() -> int:
    return int(time.perf_counter() * 1000)

def _estimate_tokens(text: str) -> int:
    # Deterministic heuristic: max of words*ratio and chars/4, rounded down
    words = len(text.split())
    by_words = int(words * DEFAULT_TOKEN_RATIO)
    by_chars = len(text) // 4
    return max(by_words, by_chars)

def _ensure_str_task(task: Union[str, Dict[str, Any]]) -> Tuple[str, Dict[str, Any]]:
    """
    Normalize task into two forms:
    - raw_text: the primary text to analyze
    - task_meta: dict with optional 'objective', 'constraints', 'inputs', 'type', 'action', etc.
    """
    if isinstance(task, str):
        raw_text = task.strip()
        meta: Dict[str, Any] = {}
        return raw_text, meta

    if not isinstance(task, dict):
        raise TypeError("task must be a string or a dict")

    raw_text = str(task.get("prompt") or task.get("text") or task.get("objective") or "").strip()
    meta = {
        "objective": task.get("objective"),
        "constraints": task.get("constraints"),
        "inputs": task.get("inputs"),
        "type": task.get("type") or task.get("action"),
        "prompt": task.get("prompt") or task.get("text"),
    }
    # Include all fields for downstream rules if needed
    for k, v in task.items():
        if k not in meta:
            meta[k] = v
    return raw_text, meta

def _get_tools_registry(context: Optional[Dict[str, Any]]) -> ToolsRegistry:
    registry: ToolsRegistry = {}
    if not context:
        return registry

    tools = context.get("tools")
    if not tools:
        return registry

    # Accept a list of tool specs or dict mapping names->callables/specs
    if isinstance(tools, dict):
        for name, spec in tools.items():
            if callable(spec):
                registry[name] = spec
            elif isinstance(spec, dict) and callable(spec.get("callable")):
                registry[name] = spec["callable"]
    elif isinstance(tools, list):
        for spec in tools:
            if not isinstance(spec, dict):
                continue
            name = spec.get("name")
            func = spec.get("callable")
            if isinstance(name, str) and callable(func):
                registry[name] = func
    return registry

def _invoke_tool(name: str, args: Dict[str, Any], registry: ToolsRegistry) -> Tuple[Optional[Any], Optional[str]]:
    try:
        func = registry.get(name)
        if not func:
            return None, f"Tool '{name}' not found"
        result = func(**args) if args else func()  # simple invocation pattern
        return result, None
    except Exception as e:
        return None, f"Tool '{name}' invocation failed: {e}"

def _get_max_output_tokens(context: Optional[Dict[str, Any]], constraints_meta: Any) -> Optional[int]:
    # Resolve from context or constraints
    if context and isinstance(context.get("max_output_tokens"), int):
        return max(0, context["max_output_tokens"])
    # Constraints could be a dict or number
    if isinstance(constraints_meta, dict):
        limit = constraints_meta.get("max_output_tokens")
        if isinstance(limit, int):
            return max(0, limit)
    if isinstance(constraints_meta, (int, float)):
        return max(0, int(constraints_meta))
    return None

def _apply_constraints(output: str, limit_tokens: Optional[int]) -> Tuple[str, bool]:
    if limit_tokens is None:
        return output, False
    if limit_tokens <= 0:
        return "", True
    est = _estimate_tokens(output)
    if est <= limit_tokens:
        return output, False
    # Truncate deterministically by characters to meet approximate token budget.
    # Back-calculate allowed characters ≈ limit_tokens * 4 (inverse of chars/4 heuristic),
    # then apply a small safety margin to avoid borderline fluctuations.
    max_chars = max(0, (limit_tokens * 4) - 8)
    truncated = (output[:max_chars].rstrip() + "… [truncated to meet constraints]") if max_chars > 0 else ""
    return truncated, True

def _apply_safety_redaction(text: str) -> Tuple[str, bool]:
    lowered = text.lower()
    fired = False
    for term in BLOCKLIST:
        if term in lowered:
            fired = True
            # Redact all case-insensitive occurrences
            pattern = re.compile(re.escape(term), flags=re.IGNORECASE)
            text = pattern.sub("[redacted]", text)
            lowered = text.lower()
    return text, fired

def _get_session_id(context: Optional[Dict[str, Any]]) -> str:
    if context and isinstance(context.get("session_id"), str) and context["session_id"].strip():
        return context["session_id"]
    return "__default_session__"

def _get_memory(session_id: str, capacity: int = DEFAULT_MEMORY_CAPACITY) -> Deque[Dict[str, Any]]:
    dq = _MEMORY.get(session_id)
    if dq is None:
        dq = deque(maxlen=capacity)
        _MEMORY[session_id] = dq
    return dq

def _gather_keywords(text: str, limit: int = 20) -> List[str]:
    tokens = [t.lower() for t in re.findall(r"[A-Za-z0-9_]+", text)]
    # Simple de-dup preserving order
    seen = set()
    out: List[str] = []
    for t in tokens:
        if t not in seen:
            seen.add(t)
            out.append(t)
        if len(out) >= limit:
            break
    return out

def _memory_retrieve_hint(session_id: str, current_text: str, enable_memory: bool) -> Optional[str]:
    if not enable_memory:
        return None
    dq = _get_memory(session_id)
    if not dq:
        return None
    cur_kw = set(_gather_keywords(current_text))
    best_match = None
    best_overlap = 0
    for item in dq:
        prev_text = str(item.get("task") or "")
        prev_out = str(item.get("output") or "")
        ov = len(cur_kw.intersection(set(_gather_keywords(prev_text))))
        if ov > best_overlap and prev_out:
            best_overlap = ov
            best_match = prev_out
    return best_match

# ---------------- Rule predicates and handlers ----------------

@dataclass(frozen=True)
class Rule:
    id: str
    predicate: Callable[[str, Dict[str, Any], Dict[str, Any]], bool]
    handler: Callable[[str, Dict[str, Any], Dict[str, Any]], str]
    terminal: bool = False  # if True, stops further rule application after firing

def _pred_plan(text: str, meta: Dict[str, Any], ctx: Dict[str, Any]) -> bool:
    if meta.get("type") in {"plan"}:
        return True
    objective = str(meta.get("objective") or text).lower()
    constraints = str(meta.get("constraints") or "").lower()
    hints = ("plan", "milestone", "steps")
    return any(h in objective for h in hints) or any(h in constraints for h in hints)

def _handle_plan(text: str, meta: Dict[str, Any], ctx: Dict[str, Any]) -> str:
    objective = meta.get("objective") or text
    inputs = meta.get("inputs")
    # short deterministic numbered plan with 4-6 steps bounded
    base_steps = [
        "Clarify objectives and constraints",
        "Collect and structure inputs",
        "Execute core tasks (compute/lookup/extract) under constraints",
        "Summarize findings and risks",
        "Review constraints and safety, finalize output",
    ]
    if meta.get("type") == "plan" or "summarize" in str(objective).lower():
        steps = base_steps
    else:
        steps = base_steps[:4]
    if inputs:
        steps = steps[:4] + ["Integrate provided inputs and re-validate constraints"]
    return "\n".join(f"{i+1}. {s}" for i, s in enumerate(steps))

def _pred_summarize(text: str, meta: Dict[str, Any], ctx: Dict[str, Any]) -> bool:
    if meta.get("type") in {"summarize"}:
        return True
    threshold = int(ctx.get("summary_len", DEFAULT_SUMMARY_LEN))
    return len(text) > threshold or "summarize" in text.lower()

def _handle_summarize(text: str, meta: Dict[str, Any], ctx: Dict[str, Any]) -> str:
    # Extractive lite: keep first sentence-like chunks until a budget
    limit = int(ctx.get("summary_len", DEFAULT_SUMMARY_LEN))
    # Split into sentences by simple regex; deterministic
    sentences = re.split(r"(?<=[.!?])\s+", text.strip())
    out: List[str] = []
    total = 0
    for s in sentences:
        if not s:
            continue
        if total + len(s) + 1 > limit:
            break
        out.append(s)
        total += len(s) + 1
        if total >= limit:
            break
    if not out:
        out = [text[:limit]]
    # Slightly compress whitespace
    summary = " ".join(x.strip() for x in out)
    return summary

def _pred_extract(text: str, meta: Dict[str, Any], ctx: Dict[str, Any]) -> bool:
    # Detect "Extract name and date" or presence of colon-delimited key:value patterns
    if meta.get("type") in {"extract"}:
        return True
    lower = text.lower()
    if re.search(r"\bextract\b.*\b(name|date|email|id|value|amount)\b", lower):
        return True
    # Generic key:value (avoid false positives where the "key" looks like a long instruction)
    return bool(re.search(r"\b(?:name|date|email|id|value|amount)\b\s*:\s*[^,\n]+", lower)) or bool(
        re.search(r"\b[A-Za-z][A-Za-z0-9_ ]{0,30}:\s*[^,\n]+", text)
    )

def _handle_extract(text: str, meta: Dict[str, Any], ctx: Dict[str, Any]) -> str:
    # Parse explicit common fields first
    result: Dict[str, str] = {}
    m_name = re.search(r"\bName:\s*([^,\n]+)", text, flags=re.IGNORECASE)
    if m_name:
        result["name"] = m_name.group(1).strip()
    m_date = re.search(r"\bDate:\s*([0-9]{4}-[0-9]{2}-[0-9]{2})", text, flags=re.IGNORECASE)
    if m_date:
        result["date"] = m_date.group(1).strip()

    # Then parse other simple key: value pairs but skip instructional keys like "extract ... from"
    pairs = re.findall(r"([A-Za-z][A-Za-z0-9_ ]{0,30}):\s*([^\n,]+)", text)
    for k, v in pairs:
        key_norm = k.strip().lower()
        # Skip instructional prefixes
        if key_norm.startswith("extract ") or " from" in key_norm:
            continue
        key = key_norm.replace(" ", "_")
        val = v.strip()
        # Do not overwrite explicit fields captured above
        if key not in result:
            result[key] = val

    return json.dumps(result, ensure_ascii=False, separators=(",", ":"))

def _pred_compute(text: str, meta: Dict[str, Any], ctx: Dict[str, Any]) -> bool:
    # Arithmetic expression detection, e.g. "2+2*3", "Compute 12*(3+4)"
    # Be conservative to avoid triggering on natural language that contains numbers.
    if meta.get("type") in {"compute"}:
        return True
    lower = text.strip().lower()
    if lower.startswith("compute "):
        return True
    # Pure math expression only (digits/operators/space/paren); otherwise ignore
    return re.fullmatch(r"[0-9\.\s\+\-\*\/\(\)\^]+", text.strip()) is not None

def _safe_eval_expr(expr: str) -> Optional[float]:
    # Deterministic safe arithmetic evaluation supporting + - * / ^ and parentheses
    # Replace ^ with ** for exponentiation if present
    expr = expr.replace("^", "**")
    # Only allow digits, operators, dot, spaces and parentheses
    if not re.fullmatch(r"[0-9\.\s\+\-\*\/\(\)\*]*", expr):
        return None
    try:
        # Restricted eval environment
        return float(eval(expr, {"__builtins__": {}}, {}))
    except Exception:
        return None

def _handle_compute(text: str, meta: Dict[str, Any], ctx: Dict[str, Any]) -> str:
    tools: ToolsRegistry = ctx.get("tools_registry", {})
    used: List[Dict[str, Any]] = ctx.setdefault("used_tools", [])

    # Determine a clean arithmetic expression to evaluate/tool-call
    stripped = text.strip()
    if re.fullmatch(r"[0-9\.\s\+\-\*\/\(\)\^]+", stripped):
        expr = stripped
    else:
        spans = re.findall(r"\d[\d\.\s\+\-\*\/\(\)\^]*\d", text)
        expr = max(spans, key=len) if spans else ""

    # Prefer external calculator tool if available; if no clean expr, pass the stripped text to allow tool errors to surface
    if "calculator" in tools:
        args = {"expression": (expr or stripped)}
        result, err = _invoke_tool("calculator", args, tools)
        # Format numeric results deterministically
        formatted = None
        if err is None and result is not None:
            try:
                if isinstance(result, (int, float)) and float(result).is_integer():
                    formatted = str(int(float(result)))
                else:
                    formatted = str(result)
            except Exception:
                formatted = str(result)
        used.append({"name": "calculator", "args": args, "result": formatted, "error": err})
        if err is None and formatted is not None:
            ctx["compute_success"] = True
            return f"Result: {formatted}"

    # Fallback: safe, local evaluation using extracted expr
    val = _safe_eval_expr(expr) if expr else None
    if val is not None:
        ctx["compute_success"] = True
        return f"Result: {int(val) if (float(val).is_integer()) else val}"
    return "Could not compute expression"

def _pred_lookup(text: str, meta: Dict[str, Any], ctx: Dict[str, Any]) -> bool:
    # If context provides lookup_table and we have a key hit
    table = ctx.get("lookup_table")
    if not isinstance(table, dict) or not text:
        return False
    key = text.strip().lower()
    return key in table

def _handle_lookup(text: str, meta: Dict[str, Any], ctx: Dict[str, Any]) -> str:
    table = ctx.get("lookup_table") or {}
    key = text.strip().lower()
    return str(table.get(key, ""))

def _pred_constraint_enforcer(_text: str, _meta: Dict[str, Any], ctx: Dict[str, Any]) -> bool:
    # Always applicable as a finalizing step when a limit exists; evaluated after body generation
    return bool(ctx.get("max_output_tokens") is not None)

def _handle_constraint_enforcer(text: str, _meta: Dict[str, Any], ctx: Dict[str, Any]) -> str:
    limited, _ = _apply_constraints(text, ctx.get("max_output_tokens"))
    return limited

def _pred_safety(_text: str, _meta: Dict[str, Any], ctx: Dict[str, Any]) -> bool:
    # Always applicable as a finalizing step
    return True

def _handle_safety(text: str, _meta: Dict[str, Any], ctx: Dict[str, Any]) -> str:
    redacted, _ = _apply_safety_redaction(text)
    return redacted

# Priority-ordered deterministic rules
_RULES: List[Rule] = [
    Rule(id="RULE_PLAN", predicate=_pred_plan, handler=_handle_plan, terminal=False),
    Rule(id="RULE_SUMMARIZE", predicate=_pred_summarize, handler=_handle_summarize, terminal=False),
    Rule(id="RULE_EXTRACT", predicate=_pred_extract, handler=_handle_extract, terminal=True),  # extraction is terminal
    Rule(id="RULE_COMPUTE", predicate=_pred_compute, handler=_handle_compute, terminal=True),
    Rule(id="RULE_LOOKUP", predicate=_pred_lookup, handler=_handle_lookup, terminal=True),
    # Finalization rules (post-processing)
    Rule(id="RULE_CONSTRAINT_ENFORCER", predicate=_pred_constraint_enforcer, handler=_handle_constraint_enforcer, terminal=False),
    Rule(id="RULE_SAFETY", predicate=_pred_safety, handler=_handle_safety, terminal=False),
]

# ---------------- Core engine ----------------

def decide(task: Union[Dict[str, Any], str], context: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
    """
    Deterministic, rule-based baseline decision function.

    Input:
      - task: dict or string
      - context: optional dict with keys:
          tools: list[{"name": str, "callable": callable, "description": str, "schema": dict|None}] | dict
          max_output_tokens: int
          enable_memory: bool
          session_id: str
          lookup_table: dict[str, str]
          summary_len: int (characters)
    Returns:
      {
        "status": "success" | "failed",
        "output": str,
        "reasoning": [str, ...],
        "applied_rules": [str, ...],
        "used_tools": [{"name": "...", "args": {...}, "result": "...", "error": "..."}],
        "metrics": {"duration_ms": int, "tokens_est": int},
        "memory": {"recent": [...]}  # included when memory enabled
      }
    """
    start = _now_ms()
    used_tools: List[Dict[str, Any]] = []
    reasoning: List[str] = []
    applied_rules: List[str] = []
    status = "success"
    output: str = ""
    compute_success = False

    # Normalize input
    try:
        raw_text, meta = _ensure_str_task(task)
    except Exception as e:
        return {
            "status": "failed",
            "output": "",
            "reasoning": [f"Invalid task input: {e}"],
            "applied_rules": [],
            "used_tools": [],
            "metrics": {"duration_ms": max(0, _now_ms() - start), "tokens_est": 0},
            "memory": {"recent": []},
        }

    if not raw_text and not any(meta.get(k) for k in ("objective", "inputs")):
        return {
            "status": "failed",
            "output": "",
            "reasoning": ["Empty input; cannot proceed"],
            "applied_rules": [],
            "used_tools": [],
            "metrics": {"duration_ms": max(0, _now_ms() - start), "tokens_est": 0},
            "memory": {"recent": []},
        }

    ctx: Dict[str, Any] = dict(context or {})
    ctx["tools_registry"] = _get_tools_registry(ctx)
    ctx["used_tools"] = used_tools
    ctx["lookup_table"] = ctx.get("lookup_table") if isinstance(ctx.get("lookup_table"), dict) else None
    ctx["summary_len"] = ctx.get("summary_len", DEFAULT_SUMMARY_LEN)

    # Resolve constraints
    max_tokens = _get_max_output_tokens(context, meta.get("constraints"))
    ctx["max_output_tokens"] = max_tokens

    # Memory hinting
    session_id = _get_session_id(context)
    enable_memory = bool(ctx.get("enable_memory"))
    hint = _memory_retrieve_hint(session_id, raw_text or str(meta.get("objective") or ""), enable_memory)
    if hint:
        reasoning.append("Found related prior interaction; using as hint")
    else:
        reasoning.append("No relevant prior memory found")

    # Strategy selection and rule application
    stop = False
    max_steps = int(ctx.get("max_rule_steps", DEFAULT_MAX_RULE_STEPS))
    # Start with a draft: if lookup or compute yields a final answer, they'll overwrite
    draft = meta.get("objective") or raw_text

    try:
        steps = 0
        for rule in _RULES:
            if steps >= max_steps:
                reasoning.append("Max rule applications reached; stopping")
                break
            if rule.id in {"RULE_CONSTRAINT_ENFORCER", "RULE_SAFETY"}:
                # defer finalization until after a body exists; still run if output is empty (constraints may zero it)
                pass
            # Evaluate predicate
            try:
                if rule.predicate(raw_text, meta, ctx):
                    applied_rules.append(rule.id)
                    reasoning.append(f"Applied {rule.id}")
                    # Handler transforms output; some rules are terminal (final answer chosen)
                    candidate = rule.handler(raw_text if not output else output, meta, ctx)
                    output = candidate
                    # Track compute success deterministically
                    if rule.id == "RULE_COMPUTE" and isinstance(output, str) and output.strip().startswith("Result:"):
                        compute_success = True
                    steps += 1
                    if rule.terminal:
                        # After terminal, still allow finalization rules to run
                        # but don't run other non-finalization rules
                        break
            except Exception as re_err:
                # Log and continue; do not crash the engine
                _logger.warning("Rule %s failed: %s", rule.id, re_err)
                reasoning.append(f"Rule {rule.id} error, continuing")
                steps += 1
                continue

        # Finalization: constraint enforcer and safety always run
        if "RULE_CONSTRAINT_ENFORCER" not in applied_rules and _pred_constraint_enforcer(output, meta, ctx):
            applied_rules.append("RULE_CONSTRAINT_ENFORCER")
            reasoning.append("Applied RULE_CONSTRAINT_ENFORCER")
            output = _handle_constraint_enforcer(output, meta, ctx)

        # Safety redaction
        redacted, fired = _apply_safety_redaction(output)
        if fired:
            if "RULE_SAFETY" not in applied_rules:
                applied_rules.append("RULE_SAFETY")
                reasoning.append("Applied RULE_SAFETY")
        output = redacted

        # Edge case: enforce conflicting constraints (e.g., max_output_tokens = 0)
        if max_tokens is not None and max_tokens <= 0:
            output = ""  # already enforced by constraint handler, but ensure determinism
            if "RULE_CONSTRAINT_ENFORCER" not in applied_rules:
                applied_rules.append("RULE_CONSTRAINT_ENFORCER")
                reasoning.append("Applied RULE_CONSTRAINT_ENFORCER")

    except Exception as e:
        status = "failed"
        reasoning.append(f"Engine error: {e}")
        if not output:
            output = ""

    # Final status: fail only when a tool error occurred and we could not compute a result.
    # Determine final status deterministically:
    # - Success if we produced any non-empty output
    # - Failure only if a tool error occurred and we failed to produce a meaningful compute result
    has_output = bool((output or "").strip())
    tool_error = any(isinstance(u, dict) and u.get("error") for u in used_tools)
    comp_fail = output.strip().lower() == "could not compute expression"
    if tool_error and (not has_output or comp_fail):
        status = "failed"
    else:
        status = "success"
    # Strong guarantees of success when compute actually succeeded
    if ctx.get("compute_success") or (any(r == "RULE_COMPUTE" for r in applied_rules) and str(output).strip().startswith("Result:")):
        status = "success"
    # If calculator tool produced a result (even when other tools failed), prefer success
    if any(isinstance(u, dict) and u.get("name") == "calculator" and u.get("result") not in (None, "") for u in used_tools):
        status = "success"

    # Update episodic memory
    memory_recent: List[Dict[str, Any]] = []
    if enable_memory:
        dq = _get_memory(session_id)
        interaction = {"task": raw_text or str(meta.get("objective") or ""), "output": output}
        dq.append(interaction)
        memory_recent = list(dq)

    duration_ms = max(0, _now_ms() - start)
    tokens_est = _estimate_tokens(output)

    # Final corrective: any explicit compute result forces success
    if compute_success or str(output).strip().startswith("Result:"):
        status = "success"

    return {
        "status": status,
        "output": output,
        "reasoning": reasoning,
        "applied_rules": applied_rules,
        "used_tools": used_tools,
        "metrics": {"duration_ms": duration_ms, "tokens_est": tokens_est},
        "memory": {"recent": memory_recent} if enable_memory else {"recent": []},
    }


async def decide_async(task: Union[Dict[str, Any], str], context: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
    # Lightweight async wrapper for consistency with async-capable orchestrators
    loop = asyncio.get_event_loop()
    return await loop.run_in_executor(None, decide, task, context)
